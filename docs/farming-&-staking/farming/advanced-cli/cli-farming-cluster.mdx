---
title: Farming Cluster
sidebar_position: 2
description: How to Set Up and Configure a Farming Cluster
slug: /farming/advanced-cli/cluster
keywords:
    - Farming Cluster
    - Farmer
    - Farming
    - CLI
    - Cluster
    - Docker
---


The Farming Cluster is designed for larger farmers, addressing the challenges of scaling effectively. It consists of four main components, all interconnected through a NATS Server.

This setup enables powerful remote computing capabilities. For example, if a computer is ideal for farming but not for plotting, you can run the farming component on that machine while utilizing one or more remote machines for plotting. This ensures continuous plotting and replotting across multiple farms, optimizing the use of plotters until all sectors are fully plotted and replotted.

<div style={{ textAlign: 'center' }}>

```mermaid
flowchart
NATS((NATS Server))
NATS  <-->  Controller(Controller)
NATS  <-->  Cache(Cache)
NATS  <-->  Farmer(Farmer)
NATS  <-->  Plotter(Plotter)
```
</div>

## Networking Considerations

Farming Cluster employs a modular architecture for operating a farm, where each component can function independently and can be scaled by running multiple instances of a component for added scalability and redundancy. As such, it is essential to ensure sufficient LAN bandwidth to facilitate efficient communication of this data transfer across your network between these components.

:::caution Networking Requirements

A 1 Gbit network connection is likely insufficient for this traffic, especially when using GPU plotting resources or multiple plotters. In such cases, a 2.5 Gbit connection should be considered the minimum, with an upgrade to 10 Gbit or higher for larger clusters.

:::

:::info Bandwidth Optimization Suggestion

You can reduce LAN bandwidth usage by running the NATS, Controller, Cache, and Plotter components on the same machine. This setup allows most data transfer to occur over the local loopback interface.

:::

## Key Benefits

- **Remote Compute Capability**  
  Multiple PCs can contribute their CPU and GPU resources for plotting and replotting, without the need to store farm plots locally.

- **Redundancy**  
  Running multiple computers for each process increases redundancy and system resilience.

- **Bandwidth Efficiency**  
  Centralized storage of the piece cache helps conserve WAN bandwidth.
  
- **Additional Space**  
  Relocating the piece sync cache to a central location frees up an additional 1% of plot capacity for farming, compared to the Standalone Farmer.


## NATS

At the core of Farming Cluster is a third-party software called [NATS](https://nats.io/), which is used for communication between the farming components.

The simplest way to install and run NATS is via Docker. 

<details open>
<summary>Set Up and Configure NATS</summary>

1. Create and save a `nats.config` configuration file with the following:

```bash title="nats.conf"
max_payload = 2MB
```
2. Start NATS with Docker:

```bash
docker run \
    --name nats \
    --restart unless-stopped \
    --publish 4222:4222 \
    --volume /path/to/nats.config:/nats.config:ro \
    nats -c /nats.config
```

</details>

---


## Component Configuration


Configuring Cluster Farming is similar to setting up the Standalone Farmer, but each component must be configured according to the cluster setup you want to create. Keep in mind that all components communicate with one another through the NATS server you configured earlier. Below are the essential parameters needed to establish a functional cluster.

<details open>
<summary>Controller (Manages node communication and orchestrates other components.)</summary>

The first component to start is the Controller. It connects to a single node, and you must specify the node's location on the network.

:::caution Proper Port Forwarding

For your cluster to be reachable, open and forward the default port `30533` to the Controller. If you've changed the port or are using multiple controllers, set it with `--listen-on /ip4/0.0.0.0/tcp/<port>`.

If you have an IPv6 address but no public IPv4 address, setting the listen port to with `--listen-on /ip6/::/tcp/<port>`. to accept IPv6 connections is highly recommended.

Refer to our guide on [Port Forwarding](/farming/guides/port-config).

:::

```bash
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    controller \
        --base-path /path/to/controller-dir \
        --node-rpc-url ws://<node_ip>:<rpc_port>
```

Replace the following placeholders:

- `<nats_ip>`: The IP address of your NATS server.
- `/path/to/controller-dir`: The path where the controller's peer network details will be saved.
- `<node_ip>` and `<rpc_port>`: Your node's IP address and RPC port.

<details>
<summary>Common Paramaters</summary>

Refer to `./subspace-farmer cluster controller --help` for an explanation of each option and its default values.

```shell
--listen-on /ip4/0.0.0.0/tcp/<port>
--listen-on /ip6/::1/tcp/<port>

--cache-group
--in-connections
--out-connections
--pending-in-connections
--pending-out-connections
```
</details>

</details>

<details open>
<summary>Cache (Downloads sector data from DSN peers and serves it to the plotter.)</summary>

:::caution Cache Size

The Cache stores the blockchain's Archive History. For optimal performance, the cache must be large enough to hold this data locally. If the data isn't available in the cache, plotting may slow down as it has to be fetched from peers over the DSN. Currently, we recommend a minimum of 200GiB.

The current Archive History Size can be found in the top cards on [Astral Block Explorer](https://astral.autonomys.xyz).

:::

```bash
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    cache \
        path=/path/to/cache,size=<size>
```

Replace the following placeholders:

- `<nats_ip>`: The IP address of your NATS server.
- `/path/to/cache` and `<size>`: The path and size for cache storage. Multiple caches are supported on a single Cache component:

    ```
    path=/path/to/cache1,size=<size> \
    path=/path/to/cache2,size=<size>
    ```

<details>
<summary>Common Paramaters</summary>

Refer to `./subspace-farmer cluster cache --help` for an explanation of additional paramaters and their default values.

```shell
--cache-group
```
</details>

</details>

<details open>
<summary>Plotter (Generates and uploads plotted sectors, downloading pieces from cache as needed)</summary>

```bash
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    plotter
```

Replace the following placeholders:

- `<nats_ip>`: The IP address of your NATS server.

<details>
<summary>Common Paramaters</summary>

Refer to `./subspace-farmer cluster plotter --help` for an explanation of paramaters and their default values.

</details>

</details>

<details open>
<summary>Farmer (Manages farms, audits, and retrieves plotted pieces. Requests sector plotting from the Plotter.)</summary>

```bash
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    farmer \
        --reward-address <reward_address> \
        path=/path/to/farm,size=<size>
```

Replace the following placeholders:

- `<nats_ip>`: The IP address of your NATS server.
- `<reward_address>`: The reward address where your winning rewards will be sent.
- `/path/to/farm` and `<size>`: The path and size for storing your plots. You can add multiple plots to your farm:

    ```
    path=/path/to/farm1,size=<size> \
    path=/path/to/farm2,size=<size>
    ```

<details>
<summary>Common Paramaters</summary>

Refer to `./subspace-farmer cluster farmer --help` for an explanation of each option and its default values.

```shell
--create
```
</details>

</details>

### Grouping Components

<details open>
<summary>You can run Farming Cluster components individually or combine them to run simultaneously.</summary>

```bash
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    controller \
        --base-path /path/to/controller-dir \
        --node-rpc-url ws://<node_ip>:<rpc_port>
    -- \
    cache \
        path=/path/to/cache,size=<size>
    -- \
    plotter
    -- \
    farmer \
        --reward-address <reward_address> \
        path=/path/to/farm,size=<size>
```

</details>

---


## Advanced Topics


### NATS Cluster

<details open>
<summary>Just like every other component in the Farming Cluster, it is possible to have redundent NATS servers. Doing so requires an extra step of configuring those NATS servers in their own cluster.</summary>

Check out the [NATS.io Cluster Guide](https://docs.nats.io/running-a-nats-service/configuration/clustering) for further details.

<div style={{ textAlign: 'center' }}>

```mermaid
flowchart
    A[Farming Cluster Components] <--> B((NATS Server 1))
    A[Farming Cluster Components] <--> C((NATS Server 2))
```

</div>

<details>
<summary>Example</summary>

```bash
./subspace-farmer cluster \
    controller \
        --nats-server=nats://<nats_ip_1>:4222 \
        --nats-server=nats://<nats_ip_2>:4222 \
        --base-path /path/to/controller-dir \
        --node-rpc-url ws://<node_ip>:<rpc_port>        
```

</details>

</details>


### Multiple Components

<details open>
<summary>This will demonstrate how to run multiple components in one Farming Cluster: (1) NATS Server, (2) Controllers, (2) Caches, (2) Plotters, and (3) Farmers.</summary>

<div style={{ textAlign: 'center' }}>

```mermaid
flowchart
NATS((NATS Server))
Controller1(Controller 1)
Controller2(Controller 2)
Cache1(Cache 1)
Cache2(Cache 2)
Plotter1(Plotter 1)
Plotter2(Plotter 2)
Farmer1(Farmer 1)
Farmer2(Farmer 2)
Farmer3(Farmer 3)

Controller1  <-->  NATS
Controller2  <-->  NATS

Cache1  <-->  NATS
Cache2  <-->  NATS

Plotter1  <-->  NATS
Plotter2  <-->  NATS

Farmer1 <-->  NATS
Farmer2 <-->  NATS
Farmer3 <-->  NATS

```

</div>

:::caution Multiple Cache Groups

Each cache group must have a unique name, and controllers can be assigned one or more. Specify an alphanumeric name for each using `--cache-group <group_name>`.

:::

<details>
<summary>Example</summary>

```bash title="Controller #1"
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    controller \
        --base-path /path/to/controller-dir \
        --cache-group <group_1> \
        --cache-group <group_2> \
        --node-rpc-url ws://<node_ip>:<rpc_port>
```

```bash title="Controller #2"
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    controller \
        --base-path /path/to/controller-dir \
        --cache-group <group_2> \
        --node-rpc-url ws://<node_ip>:<rpc_port>
```

```bash title="Cache #1"
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    cache \
        --cache-group <group_1> \
        path=/path/to/cache,size=<size>
```

```bash title="Cache #2"
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    cache \
        --cache-group <group_2> \
        path=/path/to/cache,size=<size>
```

```bash title="Plotter #1"
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    plotter
```

```bash title="Plotter #2"
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    plotter
```

```bash title="Farmer #1"
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    farmer \
        --reward-address <reward_address> \
        path=/path/to/farm,size=<size>
```

```bash title="Farmer #2"
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    farmer \
        --reward-address <reward_address> \
        path=/path/to/farm,size=<size>
```

```bash title="Farmer #3"
./subspace-farmer \
    cluster \
        --nats-server nats://<nats_ip>:4222 \
    farmer \
        --reward-address <reward_address> \
        path=/path/to/farm,size=<size>
```
</details>

</details>